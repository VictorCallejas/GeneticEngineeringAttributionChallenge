{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitenvvenv06b471d0c6c74f06b7ccc810f4823694",
   "display_name": "Python 3.8.2 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names = ['train_loss','train_acc','train_top10','dev_loss', 'dev_acc','dev_top10']\n",
    "def make_plot(training_stats):\n",
    "\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.set(font_scale=1.5)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Training stats')\n",
    "\n",
    "    fig.set_size_inches(25, 10)\n",
    "\n",
    "    ax1.plot(training_stats['train_loss'], 'b-o', label='training')\n",
    "    ax1.plot(training_stats['dev_loss'], 'b-o', label='validation')\n",
    "\n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss') \n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(training_stats['train_top10'], 'b-o', label='training')\n",
    "    ax2.plot(training_stats['dev_top10'], 'b-o', label='validation')\n",
    "\n",
    "    ax2.set_title(\"Top 10 Acc\")\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Top 10 Acc')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_accuracy_scorer(gt_idx, top10_idx):\n",
    "\n",
    "    aciertos = 0\n",
    "\n",
    "    for arr, gt in zip(top10_idx,gt_idx):\n",
    "        if gt in arr:\n",
    "            aciertos+=1\n",
    "            \n",
    "    top_10_accuracy =  aciertos / len(gt_idx)\n",
    "    return top_10_accuracy"
   ]
  },
  {
   "source": [
    "## DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train:  (67447, 43)\nTest:  (18816, 42)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/processed/train.csv')\n",
    "test = pd.read_csv('../data/processed/test.csv')\n",
    "print('Train: ',train.shape)\n",
    "print('Test: ',test.shape)"
   ]
  },
  {
   "source": [
    "## TOKENIZER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=67447.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93b17a99de0e4387b759dc8e1c239e3a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b6f2a318c892>\u001b[0m in \u001b[0;36mdna_to_protein\u001b[1;34m(sequences)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mseqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\Bio\\Seq.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, table, stop_symbol, to_stop, cds, gap)\u001b[0m\n\u001b[0;32m   1021\u001b[0m         return Seq(\n\u001b[1;32m-> 1022\u001b[1;33m             \u001b[0m_translate_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodon_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_symbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m         )\n",
      "\u001b[1;32mc:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\Bio\\Seq.py\u001b[0m in \u001b[0;36m_translate_str\u001b[1;34m(sequence, table, stop_symbol, to_stop, cds, pos_stop, gap)\u001b[0m\n\u001b[0;32m   2348\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2349\u001b[1;33m             \u001b[0mamino_acids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforward_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcodon\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2350\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCodonTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTranslationError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b6f2a318c892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mseqs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtrain_protein\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdna_to_protein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtest_protein\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdna_to_protein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-b6f2a318c892>\u001b[0m in \u001b[0;36mdna_to_protein\u001b[1;34m(sequences)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mseqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "\n",
    "def dna_to_protein(sequences):\n",
    "    seqs = []\n",
    "    for seq in tqdm(sequences,total=len(sequences)):\n",
    "        try:\n",
    "            seqs.append(str(Seq(seq).translate()))\n",
    "        except e:\n",
    "            print(e)\n",
    "            print(seq)\n",
    "            print('error')\n",
    "    return seqs\n",
    "\n",
    "train_protein = dna_to_protein(train.sequence)\n",
    "test_protein = dna_to_protein(test.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'corpus.txt'\n",
    "\n",
    "with open(filename,'w+') as f:\n",
    "    for i in tqdm(range(len(train_protein)),total=len(train_protein)):\n",
    "            f.write(train_protein[i])\n",
    "            f.write('\\n')\n",
    "    for i in tqdm(range(len(test_protein)),total=len(test_protein)):\n",
    "            f.write(test_protein[i])\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tokenizers import ByteLevelBPETokenizer, SentencePieceBPETokenizer\n",
    "# Initialize a tokenizer\n",
    "tokenizer = SentencePieceBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files='corpus.txt', vocab_size=5000, min_frequency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../data/features/bert/tok_especial/vocab.json',\n",
       " '../data/features/bert/tok_especial/merges.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tokenizer.save_model('../data/features/bert/tok_especial/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer.from_pretrained(\"../data/features/bert/tok/\")\n",
    "vocab_size = 2500\n",
    "\n",
    "def get_seq_emb(sequences):\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for seq in tqdm(sequences,total=len(sequences)):\n",
    "        input_ids = tokenizer.encode(seq).ids\n",
    "        emb = np.zeros(vocab_size,dtype=np.int16)\n",
    "        for id_ in input_ids:\n",
    "            emb[id_] += 1\n",
    "        df.append(emb)\n",
    "    \n",
    "    df = pd.DataFrame(df,dtype=np.int16)\n",
    "    print(df.shape)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=67447.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a70d8c27995f4a229846d0e6ed411237"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "(67447, 2500)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=18816.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd8fb5538fa44d548b8ed656b5b5674c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "(18816, 2500)\n"
     ]
    }
   ],
   "source": [
    "train_emb = get_seq_emb(train_protein)\n",
    "train_emb['sequence_id'] = train.sequence_id.values\n",
    "test_emb = get_seq_emb(test_protein)\n",
    "test_emb['sequence_id'] = test.sequence_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler = RobustScaler()\n",
    "df = pd.concat([train_emb,test_emb],axis=0)\n",
    "scaler.fit(df.iloc[:,:-1])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(train_emb.iloc[:,:-1]))\n",
    "df['sequence_id'] = train_emb['sequence_id']\n",
    "train_emb = df\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(test_emb.iloc[:,:-1]))\n",
    "df['sequence_id'] = test_emb['sequence_id']\n",
    "test_emb = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb.to_csv('../data/features/bert/tok_especial/train_emb.csv',index=False)\n",
    "test_emb.to_csv('../data/features/bert/tok_especial/test_emb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = pd.read_csv('../data/features/bert/tok_especial/train_emb.csv')\n",
    "test_emb = pd.read_csv('../data/features/bert/tok_especial/test_emb.csv')"
   ]
  },
  {
   "source": [
    "## N-GRAMS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train_ngram_features = pd.read_csv('../data/features/ngram/5_ngram_train.csv')\n",
    "test_ngram_features = pd.read_csv('../data/features/ngram/5_ngram_test.csv')\n",
    "\n",
    "print('Train: ',train_ngram_features.shape)\n",
    "print('Test: ',test_ngram_features.shape)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "%%time\n",
    "scaler = RobustScaler()\n",
    "df = pd.concat([train_ngram_features,test_ngram_features],axis=0)\n",
    "scaler.fit(df.iloc[:,1:])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(train_ngram_features.iloc[:,1:]))\n",
    "df['sequence_id'] = train_ngram_features['sequence_id']\n",
    "print(df.shape)\n",
    "train = pd.merge(train,df,how='left',on='sequence_id')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(test_ngram_features.iloc[:,1:]))\n",
    "df['sequence_id'] = test_ngram_features['sequence_id']\n",
    "print(df.shape)\n",
    "test = pd.merge(test,df,how='left',on='sequence_id')"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "## BLAST"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(66739, 6571)\n",
      "(18606, 6571)\n"
     ]
    }
   ],
   "source": [
    "path = '../data/features/blast/processed/train.csv'\n",
    "train_blast = pd.read_csv(path)\n",
    "print(train_blast.shape)\n",
    "\n",
    "path = '../data/features/blast/processed/test.csv'\n",
    "test_blast = pd.read_csv(path)\n",
    "print(test_blast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler = RobustScaler()\n",
    "df = pd.concat([train_blast,test_blast],axis=0)\n",
    "scaler.fit(df.iloc[:,:-1])\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(train_blast.iloc[:,:-1]))\n",
    "df['sequence_id'] = train_blast['sequence_id']\n",
    "train_blast = df\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(test_blast.iloc[:,:-1]))\n",
    "df['sequence_id'] = test_blast['sequence_id']\n",
    "test_blast = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(67447, 43)\n(18816, 42)\n(66739, 6571)\n(18606, 6571)\n(67447, 2501)\n(18816, 2501)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "print(train_blast.shape)\n",
    "print(test_blast.shape)\n",
    "\n",
    "print(train_emb.shape)\n",
    "print(test_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(67447, 9113)\n(18816, 9112)\n"
     ]
    }
   ],
   "source": [
    "train = pd.merge(train,train_blast,how='outer',on='sequence_id')\n",
    "test = pd.merge(test,test_blast,how='outer',on='sequence_id')\n",
    "\n",
    "train = pd.merge(train,train_emb,how='inner',on='sequence_id')\n",
    "test = pd.merge(test,test_emb,how='inner',on='sequence_id')\n",
    "\n",
    "train.fillna(0,inplace=True)\n",
    "test.fillna(0,inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "#del df, train_emb,test_emb, train_blast,test_blast, tokenizer, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['sequence','sequence_id'],inplace=True,axis=1)\n",
    "test.drop(['sequence_id','sequence'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('target',inplace=False,axis=1)\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42,sampling_strategy='not majority')\n",
    "X_res, y_res = ros.fit_resample(X, y)\n",
    "print(X_res.shape)\n",
    "\"\"\"\n",
    "#K = 5\n",
    "#skf = StratifiedKFold(n_splits=K,shuffle=True,random_state=420)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=420,stratify=y)"
   ]
  },
  {
   "source": [
    "## INCISO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_accuracy_scorer(estimator, X, y):\n",
    "\n",
    "    probas = estimator.predict_proba(X)\n",
    "    \n",
    "    top10_idx = np.argpartition(probas, -10, axis=1)[:, -10:]\n",
    "    \n",
    "    top10_preds = estimator.classes_[top10_idx]\n",
    "\n",
    "    mask = top10_preds == np.reshape(np.array(y.values.ravel()),(y.shape[0],1))\n",
    "    \n",
    "    top_10_accuracy = mask.any(axis=1).mean()\n",
    " \n",
    "    return top_10_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "skf = StratifiedKFold(n_splits=K,shuffle=True,random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f3b0b02b2ec49bbbf8ec2c7963ea230"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n--------FOLD  1\n\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-3c9db420fb90>\", line 26, in <module>\n    model.fit(X_t, y_t)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1042, in __call__\n    self.retrieve()\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\joblib\\parallel.py\", line 921, in retrieve\n    self._output.extend(job.get(timeout=self.timeout))\n  File \"C:\\Python38\\lib\\multiprocessing\\pool.py\", line 762, in get\n    self.wait(timeout)\n  File \"C:\\Python38\\lib\\multiprocessing\\pool.py\", line 759, in wait\n    self._event.wait(timeout)\n  File \"C:\\Python38\\lib\\threading.py\", line 558, in wait\n    signaled = self._cond.wait(timeout)\n  File \"C:\\Python38\\lib\\threading.py\", line 302, in wait\n    waiter.acquire()\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"C:\\Python38\\lib\\inspect.py\", line 1503, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"C:\\Python38\\lib\\inspect.py\", line 1461, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"C:\\Python38\\lib\\inspect.py\", line 708, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"C:\\Python38\\lib\\inspect.py\", line 751, in getmodule\n    f = getabsfile(module)\n  File \"C:\\Python38\\lib\\inspect.py\", line 720, in getabsfile\n    _filename = getsourcefile(object) or getfile(object)\n  File \"C:\\Python38\\lib\\inspect.py\", line 705, in getsourcefile\n    if os.path.exists(filename):\n  File \"C:\\Python38\\lib\\genericpath.py\", line 19, in exists\n    os.stat(path)\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-3c9db420fb90>\", line 26, in <module>\n    model.fit(X_t, y_t)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1042, in __call__\n    self.retrieve()\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\joblib\\parallel.py\", line 921, in retrieve\n    self._output.extend(job.get(timeout=self.timeout))\n  File \"C:\\Python38\\lib\\multiprocessing\\pool.py\", line 762, in get\n    self.wait(timeout)\n  File \"C:\\Python38\\lib\\multiprocessing\\pool.py\", line 759, in wait\n    self._event.wait(timeout)\n  File \"C:\\Python38\\lib\\threading.py\", line 558, in wait\n    signaled = self._cond.wait(timeout)\n  File \"C:\\Python38\\lib\\threading.py\", line 302, in wait\n    waiter.acquire()\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n    self.showtraceback(running_compiled_code=True)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(etype,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n    return len(records), 0\nTypeError: object of type 'NoneType' has no len()\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"C:\\Python38\\lib\\inspect.py\", line 1503, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"C:\\Python38\\lib\\inspect.py\", line 1461, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"C:\\Python38\\lib\\inspect.py\", line 708, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"C:\\Python38\\lib\\inspect.py\", line 751, in getmodule\n    f = getabsfile(module)\n  File \"C:\\Python38\\lib\\inspect.py\", line 720, in getabsfile\n    _filename = getsourcefile(object) or getfile(object)\n  File \"C:\\Python38\\lib\\inspect.py\", line 705, in getsourcefile\n    if os.path.exists(filename):\n  File \"C:\\Python38\\lib\\genericpath.py\", line 19, in exists\n    os.stat(path)\nKeyboardInterrupt\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-3c9db420fb90>\", line 26, in <module>\n    model.fit(X_t, y_t)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1042, in __call__\n    self.retrieve()\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\joblib\\parallel.py\", line 921, in retrieve\n    self._output.extend(job.get(timeout=self.timeout))\n  File \"C:\\Python38\\lib\\multiprocessing\\pool.py\", line 762, in get\n    self.wait(timeout)\n  File \"C:\\Python38\\lib\\multiprocessing\\pool.py\", line 759, in wait\n    self._event.wait(timeout)\n  File \"C:\\Python38\\lib\\threading.py\", line 558, in wait\n    signaled = self._cond.wait(timeout)\n  File \"C:\\Python38\\lib\\threading.py\", line 302, in wait\n    waiter.acquire()\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n    self.showtraceback(running_compiled_code=True)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(etype,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n    return len(records), 0\nTypeError: object of type 'NoneType' has no len()\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n    return runner(coro)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3145, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3356, in run_ast_nodes\n    self.showtraceback()\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(etype,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1335, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1210, in structured_traceback\n    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n    return len(records), 0\nTypeError: object of type 'NoneType' has no len()\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"c:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"C:\\Python38\\lib\\inspect.py\", line 1503, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"C:\\Python38\\lib\\inspect.py\", line 1461, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"C:\\Python38\\lib\\inspect.py\", line 708, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"C:\\Python38\\lib\\inspect.py\", line 754, in getmodule\n    os.path.realpath(f)] = module.__name__\n  File \"C:\\Python38\\lib\\ntpath.py\", line 664, in realpath\n    if _getfinalpathname(spath) == path:\nKeyboardInterrupt\n"
    }
   ],
   "source": [
    "test_preds = []\n",
    "\n",
    "for i, (train_index, dev_index) in tqdm(enumerate(skf.split(X, y)),total=K):\n",
    "    print('\\n--------FOLD ',i+1)\n",
    "    X_t, X_d = X.iloc[train_index], X.iloc[dev_index]\n",
    "    y_t, y_d = y[train_index], y[dev_index]\n",
    "\n",
    "    #model = xgb.XGBClassifier(n_estimators=2,objective='multi:softprob',eval_metric=\"mlogloss\",max_depth=3,tree_method='hist',gpu_id=0,verbosity=1,n_jobs=10,random_state=420)\n",
    "    model = SVC(class_weight='balanced', probability=True)\n",
    "    #model = RandomForestClassifier(n_estimators=300,max_depth=20,verbose=0,n_jobs=11,random_state=420,max_features=None)\n",
    "    \"\"\"\n",
    "    model = lightgbm.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    boosting='dart',\n",
    "    #learning_rate = 0.1,\n",
    "    #max_depth = 20,\n",
    "    n_jobs=-2,\n",
    "    silent=True,\n",
    "    random_state=420,\n",
    "    #num_leaves = 400,\n",
    "    #n_estimators = 400,\n",
    "    #bagging_fraction = 0.8,\n",
    "    #feature_fraction = 0.9\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    model.fit(X_t, y_t)\n",
    "\n",
    "    preds = model.predict(X_d)\n",
    "\n",
    "    acc = accuracy_score(y_d,preds)\n",
    "    f1 = f1_score(y_d,preds,average='macro')\n",
    "    top = top10_accuracy_scorer(model, X_d, y_d)\n",
    "\n",
    "    print('ACC: ',acc)\n",
    "    print('F1: ', f1)\n",
    "    print('TOP-10: ',top)\n",
    "\n",
    "    test_preds.append(model.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## INCISO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labs = pd.read_csv('../data/raw/train_labels.csv').columns[1:]\n",
    "\n",
    "lab_pos = dict()\n",
    "i = 0\n",
    "for lab in labs:\n",
    "    lab_pos[lab]=i\n",
    "    i+=1\n",
    "\n",
    "def get_targets(y):\n",
    "    targets = []\n",
    "    for lab in y:\n",
    "        tmp = np.zeros(len(labs))\n",
    "        idx = lab_pos[lab]\n",
    "        tmp[idx] = 1\n",
    "        targets.append(tmp)\n",
    "    targets = torch.tensor(targets)\n",
    "    print(targets.shape)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([60702, 1314])\n",
      "torch.Size([6745, 1314])\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = [torch.from_numpy(arr).float() for arr in X_train.values]\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.stack(tmp),get_targets(y_train))\n",
    "tmp = [torch.from_numpy(arr).float() for arr in X_valid.values]\n",
    "valid_dataset = torch.utils.data.TensorDataset(torch.stack(tmp),get_targets(y_valid))\n",
    "tmp = [torch.from_numpy(arr).float() for arr in test.values]\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.stack(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset, \n",
    "    batch_size = 8, \n",
    "    sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = valid_dataset, \n",
    "    batch_size = 8, \n",
    "    sampler = torch.utils.data.SequentialSampler(valid_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset, \n",
    "    batch_size = 8, \n",
    "    sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60702, 9110)\n(6745, 9110)\n(18816, 9110)\n(60702,)\n(6745,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\"\"\"\n",
    "minus target, sequence and sequence_id\n",
    "(67447, 43)40\n",
    "(18816, 42)40\n",
    "(66739, 6571)6570\n",
    "(18606, 6571)6570\n",
    "(67447, 2501)2500\n",
    "(18816, 2501)2500\n",
    "\"\"\"\n",
    "class Blast_conv(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.folder = '../models/Blast_conv/'\n",
    "\n",
    "        self.input_shape = 6570\n",
    "        self.out_shape = 1314\n",
    "\n",
    "        self.stride = 5\n",
    "        self.c1_out = 2\n",
    "        self.num_feats = 5\n",
    "        self.idx_start_blast = 40\n",
    "        self.idx_end_blast = self.idx_start_blast + self.input_shape\n",
    "\n",
    "        self.hidden_size = self.c1_out*self.out_shape\n",
    "        self.intermediate_size = self.hidden_size * 2\n",
    "\n",
    "        self.c1 = torch.nn.Conv1d(1, self.c1_out, self.num_feats, self.stride, padding = 0)\n",
    "        self.br_c1 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.dp_c1 = nn.Dropout(0.3)\n",
    " \n",
    "        self.l1 = nn.Linear(self.hidden_size,self.intermediate_size)\n",
    "        self.br_l1 = nn.BatchNorm1d(self.intermediate_size)\n",
    "        self.ac_l1 = nn.LeakyReLU()\n",
    "        self.dp_l1 = nn.Dropout(0.3)\n",
    "   \n",
    "        self.cls = nn.Linear(self.intermediate_size,self.out_shape)\n",
    "        \n",
    "    def forward(self,batch, device):\n",
    "\n",
    "        inputs = batch[0]\n",
    "        inputs = inputs[:,self.idx_start_blast:self.idx_end_blast].unsqueeze(1).to(device)\n",
    "\n",
    "        x = self.c1(inputs).flatten(1)\n",
    "        x = self.br_c1(x)\n",
    "        x = self.dp_c1(x)\n",
    "\n",
    "        x = self.l1(x)\n",
    "        x = self.br_l1(x)\n",
    "        x = self.ac_l1(x)\n",
    "        x = self.dp_l1(x)\n",
    "\n",
    "        x = self.cls(x)\n",
    "        \n",
    "        return x.cpu().float()\n",
    "\n",
    "class TokeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.folder = '../models/TokeNet/'\n",
    "\n",
    "        self.input_shape = 2500\n",
    "        self.out_shape = 1314\n",
    "\n",
    "        self.idx_start_tokens = 6570 + 40\n",
    "        self.idx_end_tokens = self.idx_start_tokens + self.input_shape\n",
    "\n",
    "        self.hidden_size = self.input_shape * 2\n",
    " \n",
    "        self.l1 = nn.Linear(self.input_shape,self.hidden_size)\n",
    "        self.br_l1 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l1 = nn.LeakyReLU()\n",
    "        self.dp_l1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.l2 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.br_l2 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l2 = nn.LeakyReLU()\n",
    "        self.dp_l2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.l3 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.br_l3 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l3 = nn.LeakyReLU()\n",
    "        self.dp_l3 = nn.Dropout(0.3)\n",
    "        \"\"\"\n",
    "        self.l4 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.br_l4 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l4 = nn.LeakyReLU()\n",
    "        self.dp_l4 = nn.Dropout(0.3)\n",
    "\n",
    "        self.l5 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.br_l5 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l5 = nn.LeakyReLU()\n",
    "        self.dp_l5 = nn.Dropout(0.3)\n",
    "        \"\"\"\n",
    "        self.cls = nn.Linear(self.hidden_size,self.out_shape)\n",
    "        \n",
    "    def forward(self,batch, device):\n",
    "\n",
    "        inputs = batch[0]\n",
    "        inputs = inputs[:,self.idx_start_tokens:].to(device)\n",
    "\n",
    "        x = self.l1(inputs)\n",
    "        x = self.br_l1(x)\n",
    "        x = self.ac_l1(x)\n",
    "        x = self.dp_l1(x)\n",
    "        \n",
    "        x = self.l2(x)\n",
    "        x = self.br_l2(x)\n",
    "        x = self.ac_l2(x)\n",
    "        x = self.dp_l2(x)\n",
    "        \n",
    "        x = self.l3(x)\n",
    "        x = self.br_l3(x)\n",
    "        x = self.ac_l3(x)\n",
    "        x = self.dp_l3(x)\n",
    "        \"\"\"\n",
    "        x = self.l4(x)\n",
    "        x = self.br_l4(x)\n",
    "        x = self.ac_l4(x)\n",
    "        x = self.dp_l4(x)\n",
    "\n",
    "        x = self.l5(x)\n",
    "        x = self.br_l5(x)\n",
    "        x = self.ac_l5(x)\n",
    "        x = self.dp_l5(x)\n",
    "        \"\"\"\n",
    "        x = self.cls(x)\n",
    "        \n",
    "        return x.cpu().float()\n",
    "\n",
    "class Sauron(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.folder = '../models/Sauron/'\n",
    "\n",
    "        self.input_shape = 9000\n",
    "        self.out_shape = 1314\n",
    "\n",
    "        self.input_size = 40 + 2500*2 + 4*1314\n",
    "        self.hidden_size = 5000\n",
    "\n",
    "        self.blast_conv = Blast_conv()#torch.load('../models/Blast_conv/50.ckpt')\n",
    "        self.blast_conv.cls = nn.Identity()\n",
    "        #for p in self.blast_conv.parameters():\n",
    "           # p.requires_grad = False\n",
    "\n",
    "        self.tokenet = TokeNet()#torch.load('../models/TokeNet/47.ckpt')\n",
    "        self.tokenet.cls = nn.Identity()\n",
    "        #for p in self.tokenet.parameters():\n",
    "            #p.requires_grad = False\n",
    " \n",
    "        self.l1 = nn.Linear(self.input_size,self.hidden_size)\n",
    "        self.br_l1 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l1 = nn.LeakyReLU()\n",
    "        self.dp_l1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.l2 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.br_l2 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l2 = nn.LeakyReLU()\n",
    "        self.dp_l2 = nn.Dropout(0.2)\n",
    "        \"\"\"\n",
    "        self.l3 = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.br_l3 = nn.BatchNorm1d(self.hidden_size)\n",
    "        self.ac_l3 = nn.LeakyReLU()\n",
    "        self.dp_l3 = nn.Dropout(0.2)\n",
    "        \"\"\"\n",
    "        self.cls = nn.Linear(self.hidden_size,self.out_shape)\n",
    "        \n",
    "\n",
    "    def forward(self,batch, device):\n",
    "\n",
    "        inputs = batch[0]\n",
    "        x1 = inputs[:,0:40].to(device)\n",
    "\n",
    "        x2 = self.blast_conv(batch,device).to(device)\n",
    "        x3 = self.tokenet(batch,device).to(device)\n",
    "\n",
    "        x = torch.cat([x1,x2,x3],dim=1)\n",
    "\n",
    "        x = self.l1(x)\n",
    "        x = self.br_l1(x)\n",
    "        x = self.ac_l1(x)\n",
    "        x = self.dp_l1(x)\n",
    "        \n",
    "        x = self.l2(x)\n",
    "        x = self.br_l2(x)\n",
    "        x = self.ac_l2(x)\n",
    "        x = self.dp_l2(x)\n",
    "        \"\"\"\n",
    "        x = self.l3(x)\n",
    "        x = self.br_l3(x)\n",
    "        x = self.ac_l3(x)\n",
    "        x = self.dp_l3(x)\n",
    "        \"\"\"\n",
    "        x = self.cls(x)\n",
    "        \n",
    "        return x.cpu().float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GeForce GTX 1070 with Max-Q Design\n_CudaDeviceProperties(name='GeForce GTX 1070 with Max-Q Design', major=6, minor=1, total_memory=8192MB, multi_processor_count=16)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0))\n",
    "model = Sauron().to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from topk.svm import SmoothTopkSVM, MaxTopkSVM \n",
    "from sklearn import metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = torch.from_numpy(compute_class_weight(class_weight='balanced',classes=labs,y=y))\n",
    "epochs = 90\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,mode='max')\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weights)#pos_weight=weights\n",
    "#criterion = MaxTopkSVM (1314,k=10,alpha=1)\n",
    "\n",
    "folder = model.folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3c205e7648c48e5a2f13b488d42be8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=7588.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9eaf55dd7ba94fd4b4d729e034b16e96"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nEpoch:  0  train_loss  0.006889829545553445  dev_loss  0.005974528589323489  train acc  0.024  train_top10  0.07324305624196896  dev_acc  0.068  dev_top10  0.14114158636026686\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=7588.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6e4159d09e44359bf6d9634fd8139e8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-5f19757a8641>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mb_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m           \u001b[0mb_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_logits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\repos\\GeneticEngineeringAttributionChallenge\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-dcb6c0cc486f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch, device)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblast_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('TRAINING...')\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "total_steps = 0\n",
    "\n",
    "optimizer.zero_grad() \n",
    "\n",
    "with tqdm(total=epochs,leave=False) as pbar:\n",
    "  for epoch_i in range(0, epochs):\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    #optimizer.zero_grad()\n",
    "    \"\"\"\n",
    "    if epoch_i == 20:\n",
    "      criterion = MaxTopkSVM(1314,alpha=1,k=10)\n",
    "    \"\"\"\n",
    "    logits = []\n",
    "    ground_truth = []\n",
    "    for step, batch in tqdm(enumerate(train_dataloader),total=len(train_dataloader),leave=False):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        b_labels = batch[1]\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "          b_logits = model(batch,device)\n",
    "        \n",
    "        loss = criterion(b_logits,b_labels.detach()).cuda()\n",
    "        \"\"\"\n",
    "        if epoch_i < 20:\n",
    "          loss = criterion(b_logits,b_labels.detach()).cuda()\n",
    "        else:\n",
    "          loss = criterion(b_logits,torch.argmax(b_labels.detach(),dim=1)).cuda()\n",
    "        \"\"\"\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        logits.extend(b_logits.detach().numpy())\n",
    "        ground_truth.extend(np.argmax(b_labels.detach().numpy(),axis=1))    \n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_steps+=1\n",
    "\n",
    "    y_top10_idx = np.argpartition(logits, -10, axis=1)[:, -10:]\n",
    "    y_labels = np.argmax(logits,axis=1)\n",
    "\n",
    "    train_top10 = top10_accuracy_scorer(ground_truth,y_top10_idx)\n",
    "    train_acc = round(metrics.accuracy_score(ground_truth,y_labels),3)\n",
    "    avg_train_loss = total_train_loss/len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_dev_loss = 0\n",
    "\n",
    "    logits = []\n",
    "    ground_truth = []\n",
    "            \n",
    "    for step, batch in enumerate(valid_dataloader):\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "    \n",
    "        b_labels = batch[1]\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "          with torch.no_grad():\n",
    "            b_logits = model(batch,device)\n",
    "        loss = criterion(b_logits,b_labels.detach()).cuda()\n",
    "        \"\"\"\n",
    "        if epoch_i < 20:\n",
    "          loss = criterion(b_logits,b_labels.detach()).cuda()\n",
    "        else:\n",
    "          loss = criterion(b_logits,torch.argmax(b_labels.detach(),dim=1)).cuda()\n",
    "        \"\"\"\n",
    "        scaler.scale(loss)\n",
    "        total_dev_loss += loss.item()\n",
    "\n",
    "        logits.extend(b_logits.float().detach().numpy())\n",
    "        ground_truth.extend(np.argmax(b_labels.detach().numpy(),axis=1))\n",
    "\n",
    "\n",
    "    y_top10_idx = np.argpartition(logits, -10, axis=1)[:, -10:]\n",
    "    y_labels = np.argmax(logits,axis=1)\n",
    "\n",
    "    test_top10 = top10_accuracy_scorer(ground_truth,y_top10_idx)\n",
    "    test_acc = round(metrics.accuracy_score(ground_truth,y_labels),3)\n",
    "    avg_dev_loss = total_dev_loss/len(valid_dataloader)\n",
    "\n",
    "    scheduler.step(test_top10)\n",
    " \n",
    "    training_stats.append(\n",
    "        {\n",
    "            'train_loss': avg_train_loss,\n",
    "            'dev_loss': avg_dev_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'train_top10':train_top10,\n",
    "            'dev_acc': test_acc,\n",
    "            'dev_top10': test_top10\n",
    "        }\n",
    "      )\n",
    "    \n",
    "    torch.save(model,folder+str(epoch_i)+'.ckpt')\n",
    "    \n",
    "    pbar.update(1)\n",
    "\n",
    "    print('\\nEpoch: ',epoch_i,' train_loss ',avg_train_loss,\n",
    "            ' dev_loss ',avg_dev_loss,\n",
    "            ' train acc ',train_acc,\n",
    "            ' train_top10 ',train_top10,\n",
    "            ' dev_acc ',test_acc,\n",
    "            ' dev_top10 ', test_top10\n",
    "          )\n",
    "\n",
    "# Show training results\n",
    "col_names = ['train_loss','train_acc','train_top10','dev_loss', 'dev_acc','dev_top10']\n",
    "training_stats = pd.DataFrame(training_stats,columns=col_names)\n",
    "make_plot(training_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "source": [
    "## SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cls = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(dataloader):\n",
    "    X = []\n",
    "    y = []\n",
    "    model.eval()\n",
    "    for step, batch in tqdm(enumerate(dataloader),total=len(dataloader),leave=False):\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                label = batch[1].detach().numpy()\n",
    "\n",
    "                x = model(batch,device).cpu().detach().numpy()\n",
    "\n",
    "                X.extend(x)\n",
    "                y.extend(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=475.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5074d1dd1ae4ed0a6ce3fb85131a5e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22914cb63924419fab404236906cd4d0"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "X_train, y_train = getFeatures(train_dataloader)\n",
    "X_test, y_test = getFeatures(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_labels(y):\n",
    "    tmp = []\n",
    "    for l in y:\n",
    "        tmp.append(labs[np.argmax(l)])\n",
    "    return np.array(tmp)\n",
    "\n",
    "y_train = t_labels(y_train)\n",
    "y_test = t_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier()\n",
    "\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(X_train)\n",
    "\n",
    "acc = accuracy_score(y_train,preds)\n",
    "f1 = f1_score(y_train,preds,average='macro')\n",
    "\n",
    "print('ACC: ',acc)\n",
    "print('F1: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,preds)\n",
    "f1 = f1_score(y_test,preds,average='macro')\n",
    "\n",
    "print('ACC: ',acc)\n",
    "print('F1: ', f1)"
   ]
  },
  {
   "source": [
    "## SUBMISSION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sauron(\n  (blast_conv): Blast_conv(\n    (c1): Conv1d(1, 2, kernel_size=(5,), stride=(5,))\n    (br_c1): BatchNorm1d(2628, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dp_c1): Dropout(p=0.2, inplace=False)\n    (l1): Linear(in_features=2628, out_features=5256, bias=True)\n    (br_l1): BatchNorm1d(5256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (ac_l1): LeakyReLU(negative_slope=0.01)\n    (dp_l1): Dropout(p=0.2, inplace=False)\n    (cls): Identity()\n  )\n  (tokenet): TokeNet(\n    (l1): Linear(in_features=2500, out_features=5000, bias=True)\n    (br_l1): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (ac_l1): LeakyReLU(negative_slope=0.01)\n    (dp_l1): Dropout(p=0.2, inplace=False)\n    (cls): Identity()\n  )\n  (l1): Linear(in_features=10296, out_features=10296, bias=True)\n  (br_l1): BatchNorm1d(10296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (ac_l1): LeakyReLU(negative_slope=0.01)\n  (dp_l1): Dropout(p=0.5, inplace=False)\n  (cls): Linear(in_features=10296, out_features=1314, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "model = torch.load('../models/Sauron/25.ckpt').to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "logits = []\n",
    "           \n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            b_logits = model(batch,device)\n",
    "            logits.extend(b_logits.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(18816, 1314)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "probas = nn.Softmax(dim=1)(torch.stack(logits)).detach().numpy()\n",
    "probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv('../data/raw/submission_format.csv', index_col='sequence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert submission_format.shape == probas.shape\n",
    "assert (labs == submission_format.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=probas, \n",
    "                             columns=labs, \n",
    "                             index=submission_format.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 00Q4V31T      012VT4JK      028IO5W2      03GRNN7N  \\\nsequence_id                                                           \nE0VFT        3.478298e-35  3.414078e-29  5.975740e-34  7.448131e-37   \nTTRK5        2.331653e-33  7.911661e-39  6.080588e-23  1.112369e-32   \n2Z7FZ        2.559014e-25  1.208792e-25  1.594670e-27  3.686608e-26   \nVJI6E        4.336091e-38  3.012792e-43  1.265286e-33  3.826587e-38   \n721FI        2.195451e-31  6.848312e-25  3.395267e-28  3.619687e-31   \n\n                 03Y3W51H      09MQV1TY      0A4AHRCT      0A9M05NC  \\\nsequence_id                                                           \nE0VFT        6.236244e-36  2.220257e-33  2.431145e-27  2.508318e-27   \nTTRK5        2.474570e-27  5.092798e-33  4.844973e-27  1.197339e-23   \n2Z7FZ        2.786990e-29  7.155357e-19  4.279096e-22  1.495801e-24   \nVJI6E        2.162204e-42  6.381429e-40  6.695681e-32  2.827487e-37   \n721FI        1.224524e-30  7.651352e-28  3.497775e-25  6.554407e-31   \n\n                 0B9GCUVV      0CL7QVG8  ...      ZQNGGY33      ZSHS4VJZ  \\\nsequence_id                              ...                               \nE0VFT        2.879273e-32  3.858228e-34  ...  6.563067e-34  6.638447e-36   \nTTRK5        9.353000e-30  5.034968e-31  ...  1.575900e-41  1.581940e-28   \n2Z7FZ        9.952289e-33  1.781663e-30  ...  3.021601e-24  1.421314e-26   \nVJI6E        5.089182e-25  2.246151e-35  ...  7.086933e-31  1.401298e-45   \n721FI        6.479980e-29  3.740214e-34  ...  9.739226e-21  9.282143e-29   \n\n                 ZT1IP3T6      ZU6860XU      ZU6TVFFU      ZU75P59K  \\\nsequence_id                                                           \nE0VFT        9.164094e-35  1.417228e-31  3.697060e-32  2.526482e-31   \nTTRK5        3.297046e-28  2.259915e-33  2.174637e-29  1.035901e-25   \n2Z7FZ        2.366701e-25  1.079008e-27  2.130436e-23  1.592272e-24   \nVJI6E        1.500304e-30  3.589339e-35  1.116611e-33  4.067254e-35   \n721FI        2.592318e-30  6.926968e-27  6.897903e-29  4.310105e-26   \n\n                 ZUI6TDWV      ZWFD8OHC      ZX06ZDZN      ZZJVE4HO  \nsequence_id                                                          \nE0VFT        3.676009e-31  2.708901e-35  2.551656e-30  2.538643e-25  \nTTRK5        5.705366e-31  2.361252e-27  7.668246e-39  2.824361e-31  \n2Z7FZ        3.443529e-25  4.201397e-27  1.017905e-25  5.172437e-21  \nVJI6E        3.975409e-31  2.709375e-35  5.380131e-32  1.093040e-32  \n721FI        2.655379e-26  1.277509e-21  1.827762e-29  1.238589e-32  \n\n[5 rows x 1314 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00Q4V31T</th>\n      <th>012VT4JK</th>\n      <th>028IO5W2</th>\n      <th>03GRNN7N</th>\n      <th>03Y3W51H</th>\n      <th>09MQV1TY</th>\n      <th>0A4AHRCT</th>\n      <th>0A9M05NC</th>\n      <th>0B9GCUVV</th>\n      <th>0CL7QVG8</th>\n      <th>...</th>\n      <th>ZQNGGY33</th>\n      <th>ZSHS4VJZ</th>\n      <th>ZT1IP3T6</th>\n      <th>ZU6860XU</th>\n      <th>ZU6TVFFU</th>\n      <th>ZU75P59K</th>\n      <th>ZUI6TDWV</th>\n      <th>ZWFD8OHC</th>\n      <th>ZX06ZDZN</th>\n      <th>ZZJVE4HO</th>\n    </tr>\n    <tr>\n      <th>sequence_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>E0VFT</th>\n      <td>3.478298e-35</td>\n      <td>3.414078e-29</td>\n      <td>5.975740e-34</td>\n      <td>7.448131e-37</td>\n      <td>6.236244e-36</td>\n      <td>2.220257e-33</td>\n      <td>2.431145e-27</td>\n      <td>2.508318e-27</td>\n      <td>2.879273e-32</td>\n      <td>3.858228e-34</td>\n      <td>...</td>\n      <td>6.563067e-34</td>\n      <td>6.638447e-36</td>\n      <td>9.164094e-35</td>\n      <td>1.417228e-31</td>\n      <td>3.697060e-32</td>\n      <td>2.526482e-31</td>\n      <td>3.676009e-31</td>\n      <td>2.708901e-35</td>\n      <td>2.551656e-30</td>\n      <td>2.538643e-25</td>\n    </tr>\n    <tr>\n      <th>TTRK5</th>\n      <td>2.331653e-33</td>\n      <td>7.911661e-39</td>\n      <td>6.080588e-23</td>\n      <td>1.112369e-32</td>\n      <td>2.474570e-27</td>\n      <td>5.092798e-33</td>\n      <td>4.844973e-27</td>\n      <td>1.197339e-23</td>\n      <td>9.353000e-30</td>\n      <td>5.034968e-31</td>\n      <td>...</td>\n      <td>1.575900e-41</td>\n      <td>1.581940e-28</td>\n      <td>3.297046e-28</td>\n      <td>2.259915e-33</td>\n      <td>2.174637e-29</td>\n      <td>1.035901e-25</td>\n      <td>5.705366e-31</td>\n      <td>2.361252e-27</td>\n      <td>7.668246e-39</td>\n      <td>2.824361e-31</td>\n    </tr>\n    <tr>\n      <th>2Z7FZ</th>\n      <td>2.559014e-25</td>\n      <td>1.208792e-25</td>\n      <td>1.594670e-27</td>\n      <td>3.686608e-26</td>\n      <td>2.786990e-29</td>\n      <td>7.155357e-19</td>\n      <td>4.279096e-22</td>\n      <td>1.495801e-24</td>\n      <td>9.952289e-33</td>\n      <td>1.781663e-30</td>\n      <td>...</td>\n      <td>3.021601e-24</td>\n      <td>1.421314e-26</td>\n      <td>2.366701e-25</td>\n      <td>1.079008e-27</td>\n      <td>2.130436e-23</td>\n      <td>1.592272e-24</td>\n      <td>3.443529e-25</td>\n      <td>4.201397e-27</td>\n      <td>1.017905e-25</td>\n      <td>5.172437e-21</td>\n    </tr>\n    <tr>\n      <th>VJI6E</th>\n      <td>4.336091e-38</td>\n      <td>3.012792e-43</td>\n      <td>1.265286e-33</td>\n      <td>3.826587e-38</td>\n      <td>2.162204e-42</td>\n      <td>6.381429e-40</td>\n      <td>6.695681e-32</td>\n      <td>2.827487e-37</td>\n      <td>5.089182e-25</td>\n      <td>2.246151e-35</td>\n      <td>...</td>\n      <td>7.086933e-31</td>\n      <td>1.401298e-45</td>\n      <td>1.500304e-30</td>\n      <td>3.589339e-35</td>\n      <td>1.116611e-33</td>\n      <td>4.067254e-35</td>\n      <td>3.975409e-31</td>\n      <td>2.709375e-35</td>\n      <td>5.380131e-32</td>\n      <td>1.093040e-32</td>\n    </tr>\n    <tr>\n      <th>721FI</th>\n      <td>2.195451e-31</td>\n      <td>6.848312e-25</td>\n      <td>3.395267e-28</td>\n      <td>3.619687e-31</td>\n      <td>1.224524e-30</td>\n      <td>7.651352e-28</td>\n      <td>3.497775e-25</td>\n      <td>6.554407e-31</td>\n      <td>6.479980e-29</td>\n      <td>3.740214e-34</td>\n      <td>...</td>\n      <td>9.739226e-21</td>\n      <td>9.282143e-29</td>\n      <td>2.592318e-30</td>\n      <td>6.926968e-27</td>\n      <td>6.897903e-29</td>\n      <td>4.310105e-26</td>\n      <td>2.655379e-26</td>\n      <td>1.277509e-21</td>\n      <td>1.827762e-29</td>\n      <td>1.238589e-32</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1314 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('../submissions/submission_mlp_sau_bl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}